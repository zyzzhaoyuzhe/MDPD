{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time, timeit\n",
    "import signal\n",
    "import scipy.io as scio\n",
    "from scipy import stats\n",
    "from scipy.sparse import coo_matrix\n",
    "from MDPD.readers import *\n",
    "from MDPD import utils, MDPD\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/media/vzhao/Data/crowdsourcing_datasets/'\n",
    "# folder = '/Users/vincent/Documents/Research/MDPD/crowdsourcing_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 39, 2)\n"
     ]
    }
   ],
   "source": [
    "reader = Crowd_Sourcing_Readers(os.path.join(folder, 'bird', 'bluebird_crowd.txt'), os.path.join(folder, 'bird', 'bluebird_truth.txt'))\n",
    "train, label = reader.data, reader.labels\n",
    "lock = np.zeros(train.shape[1:], dtype=np.bool)\n",
    "print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Crowd_Sourcing_Readers(os.path.join(folder, 'dog', 'dog_crowd.txt'), os.path.join(folder, 'dog', 'dog_truth.txt'))\n",
    "train, label = reader.data, reader.labels\n",
    "lock = np.zeros(train.shape[1:],dtype=np.bool)\n",
    "lock[:, -1] = 1\n",
    "print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Crowd_Sourcing_Readers(os.path.join(folder, 'rte', 'rte_crowd.txt'), os.path.join(folder, 'rte', 'rte_truth.txt'))\n",
    "train, label = reader.data, reader.labels\n",
    "lock = np.zeros(train.shape[1:],dtype=np.bool)\n",
    "lock[:, -1] = 1\n",
    "print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Crowd_Sourcing_Readers(os.path.join(folder, 'trec', 'trec_crowd.txt'), os.path.join(folder, 'trec', 'trec_truth.txt'))\n",
    "train, label = reader.data, reader.labels\n",
    "lock = np.zeros(train.shape[1:],dtype=np.bool)\n",
    "lock[:, -1] = 1\n",
    "print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Crowd_Sourcing_Readers(os.path.join(folder, 'web', 'web_crowd.txt'), os.path.join(folder, 'web', 'web_truth.txt'))\n",
    "train, label = reader.data, reader.labels\n",
    "lock = np.zeros(train.shape[1:],dtype=np.bool)\n",
    "lock[:, -1] = 1\n",
    "print train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSAMPLE, DIM, NVOCAB = train.shape\n",
    "EFF_NVOCAB = NVOCAB-1 if reader.is_missing_value else NVOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Mutual Information Residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Original mutual information residue (G score)\n",
    "score_origin = utils.Feature_Selection.MI_score(train, rm_diag=True, lock=lock)\n",
    "sigma_origin = score_origin.sum(axis=1)\n",
    "print np.sum(score_origin) / (DIM * (DIM-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference G Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [99,95,90,75,50]\n",
    "percentiles = [stats.chi2.ppf(x/100., (EFF_NVOCAB**2 - 1)) / (2 * NSAMPLE) for x in percentages]\n",
    "print 'Reference G statistis at {} percentile'.format(percentages)\n",
    "print percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Mutual Information Residue if use the true label as the posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to log_post\n",
    "def label2logpost(label, ncomp):\n",
    "    nsample = label.shape[0]\n",
    "    post = np.zeros((nsample, ncomp))\n",
    "    for i in xrange(nsample):\n",
    "        post[i, label[i]] = 1\n",
    "    return np.log(post)\n",
    "log_post = label2logpost(label,label.max()+1)\n",
    "utils.log_replace_neginf(log_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "score, weights = MDPD.utils.Feature_Selection.MI_score_conditional(train, log_post, rm_diag=True, lock=lock)\n",
    "score_condition = score.sum(axis=1)\n",
    "print 'Mutual Information Residue if use the true label as the posterior distribution'\n",
    "print np.sum(score_condition * weights[np.newaxis, :]) / (DIM * (DIM - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Plot] Mutual Information Residue if use the true label as the posterior distribution vs. Raw Residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = np.argsort(sigma_origin)[::-1]\n",
    "for k in xrange(train.shape[2]-1 if np.any(lock) else train.shape[2]):\n",
    "    plt.plot(score_condition[idx,k]/(DIM - 1))\n",
    "plt.plot(sigma_origin[idx] / (DIM - 1), '--')\n",
    "# plot reference G statistics\n",
    "for foo in percentiles[:3]:\n",
    "    plt.plot([0, len(score)], [foo, foo], 'c--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sigma_origin[idx] / (DIM - 1), '--')\n",
    "plt.plot(np.sum(score_condition[idx,:] * weights[np.newaxis, :], axis=1) / (DIM - 1))\n",
    "# plot reference G statistics\n",
    "for foo in percentiles[:3]:\n",
    "    plt.plot([0, len(score)], [foo, foo], 'c--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Mixture Model with Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features, sigma = utils.Feature_Selection.MI_feature_ranking(train, lock=lock)\n",
    "print features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and Mutual Information Residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntop = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MDPD/utils.py:221: RuntimeWarning: divide by zero encountered in log\n",
      "  log_second = np.log(second)\n",
      "MDPD/utils.py:222: RuntimeWarning: invalid value encountered in multiply\n",
      "  pmi = second * (log_second - log_first)\n",
      "2018-04-09 13:12:01,533 : INFO : Training an MDPD with dimension 39, 15 features, sample size 108, vocab size 2 and the target number of components 5\n",
      "MDPD/utils.py:94: RuntimeWarning: divide by zero encountered in log\n",
      "  log_votes = np.log(votes)\n",
      "2018-04-09 13:12:01,539 : INFO : iteration 0; log-likelihood (feature selection) -6.106153; log_likelihood -17.551206;information residue 0.014784\n",
      "2018-04-09 13:12:01,548 : INFO : iteration 1; log-likelihood (feature selection) -6.094866; log_likelihood -17.541042;information residue 0.014877\n",
      "2018-04-09 13:12:01,564 : INFO : iteration 2; log-likelihood (feature selection) -6.093973; log_likelihood -17.538522;information residue 0.014842\n",
      "2018-04-09 13:12:01,579 : INFO : iteration 3; log-likelihood (feature selection) -6.093430; log_likelihood -17.537130;information residue 0.014788\n",
      "2018-04-09 13:12:01,593 : INFO : iteration 4; log-likelihood (feature selection) -6.092439; log_likelihood -17.535303;information residue 0.014732\n",
      "2018-04-09 13:12:01,606 : INFO : iteration 5; log-likelihood (feature selection) -6.090625; log_likelihood -17.532123;information residue 0.014699\n",
      "2018-04-09 13:12:01,617 : INFO : iteration 6; log-likelihood (feature selection) -6.087962; log_likelihood -17.528265;information residue 0.014704\n",
      "2018-04-09 13:12:01,631 : INFO : iteration 7; log-likelihood (feature selection) -6.085501; log_likelihood -17.526307;information residue 0.014727\n",
      "2018-04-09 13:12:01,642 : INFO : iteration 8; log-likelihood (feature selection) -6.084226; log_likelihood -17.527024;information residue 0.014747\n",
      "2018-04-09 13:12:01,648 : INFO : iteration 9; log-likelihood (feature selection) -6.083820; log_likelihood -17.528585;information residue 0.014758\n",
      "2018-04-09 13:12:01,653 : INFO : iteration 10; log-likelihood (feature selection) -6.083723; log_likelihood -17.529723;information residue 0.014764\n",
      "2018-04-09 13:12:01,660 : INFO : iteration 11; log-likelihood (feature selection) -6.083703; log_likelihood -17.530333;information residue 0.014766\n",
      "2018-04-09 13:12:01,665 : INFO : iteration 12; log-likelihood (feature selection) -6.083699; log_likelihood -17.530624;information residue 0.014767\n",
      "2018-04-09 13:12:01,674 : INFO : iteration 13; log-likelihood (feature selection) -6.083698; log_likelihood -17.530757;information residue 0.014768\n",
      "2018-04-09 13:12:01,679 : INFO : iteration 14; log-likelihood (feature selection) -6.083698; log_likelihood -17.530818;information residue 0.014768\n",
      "2018-04-09 13:12:01,684 : INFO : iteration 15; log-likelihood (feature selection) -6.083698; log_likelihood -17.530845;information residue 0.014768\n",
      "2018-04-09 13:12:01,693 : INFO : iteration 16; log-likelihood (feature selection) -6.083698; log_likelihood -17.530858;information residue 0.014768\n",
      "2018-04-09 13:12:01,699 : INFO : iteration 17; log-likelihood (feature selection) -6.083698; log_likelihood -17.530863;information residue 0.014768\n",
      "2018-04-09 13:12:01,705 : INFO : iteration 18; log-likelihood (feature selection) -6.083698; log_likelihood -17.530866;information residue 0.014768\n",
      "2018-04-09 13:12:01,710 : INFO : iteration 19; log-likelihood (feature selection) -6.083698; log_likelihood -17.530867;information residue 0.014768\n",
      "2018-04-09 13:12:01,718 : INFO : iteration 20; log-likelihood (feature selection) -6.083698; log_likelihood -17.530867;information residue 0.014768\n",
      "2018-04-09 13:12:01,730 : INFO : iteration 21; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,736 : INFO : iteration 22; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,743 : INFO : iteration 23; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,754 : INFO : iteration 24; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,773 : INFO : iteration 25; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,782 : INFO : iteration 26; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,795 : INFO : iteration 27; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,800 : INFO : iteration 28; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,810 : INFO : iteration 29; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,816 : INFO : iteration 30; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,824 : INFO : iteration 31; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,829 : INFO : iteration 32; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,834 : INFO : iteration 33; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,841 : INFO : iteration 34; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,846 : INFO : iteration 35; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,851 : INFO : iteration 36; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,858 : INFO : iteration 37; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,864 : INFO : iteration 38; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,868 : INFO : iteration 39; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,876 : INFO : iteration 40; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,881 : INFO : iteration 41; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,889 : INFO : iteration 42; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,894 : INFO : iteration 43; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,899 : INFO : iteration 44; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,906 : INFO : iteration 45; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,911 : INFO : iteration 46; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,916 : INFO : iteration 47; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,926 : INFO : iteration 48; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,935 : INFO : iteration 49; log-likelihood (feature selection) -6.083698; log_likelihood -17.530868;information residue 0.014768\n",
      "2018-04-09 13:12:01,941 : INFO : NOTE: all records and stats are exported to ../tmp0_rcEX\n",
      "2018-04-09 13:12:01,942 : INFO : ACCURACY: 91.67%\n",
      "2018-04-09 13:12:01,946 : INFO : The mutual information residue (include all features) is 0.014768358283\n",
      "2018-04-09 13:12:01,948 : INFO : The mutual information residue (within selected features) is 0.0174441723022\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "model = MDPD.MDPD_standard()\n",
    "model.fit(train, ncomp=5, init='majority', verbose=True, features=Ntop, epoch=50, lock=lock)\n",
    "model.accuracy(train, label)\n",
    "model.MI_residue(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tmp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "model.change_features(train, features=range(model.dim))\n",
    "model.accuracy(train, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Plot] Mutual Information Residue vs the Residue of the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_post = model.log_posterior(train)\n",
    "score, weights = utils.Feature_Selection.MI_score_conditional(train, log_post, rm_diag=True, lock=lock)\n",
    "sigma_condition = score.sum(axis=1)\n",
    "print 'Mutual Information Residue of the model with feature selection'\n",
    "print np.sum(sigma_condition * weights[np.newaxis, :]) / (DIM * (DIM - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = np.argsort(sigma_origin)[::-1]\n",
    "for k in xrange(train.shape[2]-1 if np.any(lock) else train.shape[2]):\n",
    "    plt.plot(score_condition[idx,k]/(DIM-1))\n",
    "plt.plot(sigma_origin[idx] / (DIM-1), '--')\n",
    "# plot reference G statistics\n",
    "for foo in percentiles[:3]:\n",
    "    plt.plot([0, len(score)], [foo, foo], 'c--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sigma_origin[idx] / (DIM-1), '--')\n",
    "plt.plot(np.sum(score_condition[idx, :] * weights[np.newaxis, :], axis=1) / (DIM-1))\n",
    "# plot reference G statistics\n",
    "for foo in percentiles[:3]:\n",
    "    plt.plot([0, len(score)], [foo, foo], 'c--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Model Performance\n",
    "#### Accuracy and Mutual Information Residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic model with majority vote initialization\n",
    "model_basic = MDPD.MDPD_standard()\n",
    "model_basic.fit(train, ncomp=EFF_NVOCAB, init='majority', verbose=False, epoch=50, lock=lock)\n",
    "model_basic.accuracy(train, label)\n",
    "model_basic.MI_residue(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_post = model_basic.log_posterior(train)\n",
    "score, weights = MDPD.utils.Feature_Selection.MI_score_conditional(train, log_post, rm_diag=True, lock=lock)\n",
    "score_condition = score.sum(axis=1)\n",
    "print 'Mutual Information Residue if use the true label as the posterior distribution'\n",
    "print np.sum(score_condition * weights[np.newaxis, :]) / (DIM * (DIM - 1))\n",
    "\n",
    "print 'Mutual Information Residue (within the selected features)'\n",
    "score_select = score[features[:Ntop, np.newaxis], features[:Ntop], :]\n",
    "res_select = np.sum(score_select.sum(axis=1) * weights[np.newaxis, :]) / (Ntop * (Ntop - 1))\n",
    "print res_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Plot] Mutual Information Residue vs the Residue of the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = np.argsort(sigma_origin)[::-1]\n",
    "for k in xrange(train.shape[2]-1 if np.any(lock) else train.shape[2]):\n",
    "    plt.plot(score_condition[idx,k]/(DIM - 1))\n",
    "plt.plot(sigma_origin[idx] / (DIM - 1), '--')\n",
    "# plot reference G statistics\n",
    "for foo in percentiles[:3]:\n",
    "    plt.plot([0, len(score)], [foo, foo], 'c--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sigma_origin[idx] / (DIM - 1), '--')\n",
    "plt.plot(np.sum(score_condition[idx,:] * weights[np.newaxis, :], axis=1) / (DIM - 1))\n",
    "# plot reference G statistics\n",
    "for foo in percentiles[:3]:\n",
    "    plt.plot([0, len(score)], [foo, foo], 'c--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
